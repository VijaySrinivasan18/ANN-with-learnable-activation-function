{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Importing Necessary Library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from random import random\n",
    "from random import randrange\n",
    "from sklearn.metrics import accuracy_score\n",
    "from math import exp\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"dataset/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def loadCsv(filename):\n",
    "        trainset=pd.read_csv(filename)\n",
    "        return trainset\n",
    "\n",
    "# Normalization\n",
    "\n",
    "def normalize(dataset):\n",
    "    min_max_obj=MinMaxScaler()\n",
    "    transformed_data=min_max_obj.fit_transform(dataset)\n",
    "    return transformed_data\n",
    "\n",
    "# Convert column values to float\n",
    "def column_to_float(dataset, column):\n",
    "        return dataset[column].astype(float)\n",
    "\n",
    "#  Label encoding target variable\n",
    "\n",
    "def encode_target(dataset,target_column):\n",
    "        label_encoder=LabelEncoder()\n",
    "        label_encoded=label_encoder.fit_transform(dataset.iloc[:,target_column])\n",
    "        with open(\"artifacts/label_encoder.pickle\",\"wb\") as s:\n",
    "                pickle.dump(label_encoder,s)\n",
    "        return label_encoded\n",
    "\n",
    "# Method to create cross validation splits\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = dataset.to_numpy().tolist()\n",
    "        fold_size = int(len(dataset_copy) / n_folds)\n",
    "        for i in range(n_folds):\n",
    "                fold = list()\n",
    "                while len(fold) < fold_size:\n",
    "                        index = randrange(len(dataset_copy))\n",
    "                        fold.append(dataset_copy.pop(index))\n",
    "                dataset_split.append(fold)\n",
    "        return dataset_split\n",
    "\n",
    "#  Method to Create a neural network\n",
    "\n",
    "# Creating Neural network with 1 hidden layes\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "        network = list()\n",
    "        hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)], 'prev':[0 for i in range(n_inputs+1)]} for i in range(n_hidden)]        \n",
    "        network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random() for i in range(n_hidden + 1)],'prev':[0 for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "        network.append(output_layer)\n",
    "        #print(network)\n",
    "        # initialize parameters of activation function g(x) = k0 + k1x\n",
    "        k=[random(),random()]\n",
    "        return network,k\n",
    "\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "        activation = weights[-1]   # Weights[-1]  is Bias term\n",
    "        for i in range(len(weights)-1):\n",
    "                activation += weights[i] * inputs[i]\n",
    "        return activation\n",
    "\n",
    "\n",
    "# Transfer neuron activation     g(x) = k0 + k1x\n",
    "def transfer(activation,K):\n",
    "        return K[0]+K[1]*(activation)\n",
    "\n",
    "\n",
    "# Forward propagate input to a network output  -  Hidden Layers use Ada Acti Activation (g(x) = k0 + k1x) and output layer use Softmax\n",
    "def forward_propagate(network, row,K):\n",
    "        inputs = row\n",
    "        for index,layer in enumerate(network):\n",
    "                if index!=len(network)-1:\n",
    "                        new_inputs = []\n",
    "                        for neuron in layer:\n",
    "                                activation = activate(neuron['weights'], inputs)\n",
    "                                print(f\"Hidden Layer {index} ,Applying Ada Acti Activation\")\n",
    "                                neuron['output'] = transfer(activation,K)\n",
    "                                new_inputs.append(neuron['output'])\n",
    "                        inputs = new_inputs\n",
    "                        # print(f\"End of a layer{index}\",inputs)\n",
    "                else:\n",
    "                        print(\"Final output layer : Applying Softmax\")\n",
    "                        i=1\n",
    "                        new_inputs = []\n",
    "                        for neuron in layer:\n",
    "                                activation = activate(neuron['weights'], inputs)\n",
    "                                # print(\"Activation value\",activation)\n",
    "                                neuron['output'] = activation\n",
    "                                new_inputs.append(neuron['output'])\n",
    "                        # print(new_inputs)\n",
    "                        # inputs=new_inputs\n",
    "                        inputs = softmax(new_inputs,axis=0)   \n",
    "                        # print(\"After applying softmax\",inputs)                     \n",
    "\n",
    "                        \n",
    "        return inputs\n",
    "\n",
    "\n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "        return output * (1.0 - output)\n",
    "\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "        for i in reversed(range(len(network))):\n",
    "                layer = network[i]\n",
    "                errors = list()\n",
    "                if i != len(network)-1:\n",
    "                        for j in range(len(layer)):\n",
    "                                error = 0.0\n",
    "                                for neuron in network[i + 1]:\n",
    "                                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                                errors.append(error)\n",
    "                else:\n",
    "                        for j in range(len(layer)):\n",
    "                                neuron = layer[j]\n",
    "                                errors.append(expected[j] - neuron['output'])\n",
    "                for j in range(len(layer)):\n",
    "                        neuron = layer[j]\n",
    "                        neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "net,k=initialize_network(4,3,3)\n",
    "\n",
    "# print(forward_propagate(net,df.iloc[1,:],k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  converting Independent variables into float\n",
    "\n",
    "for col in df.columns[:-1]:\n",
    "    df[col]=column_to_float(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding  dependent variable \n",
    "\n",
    "df.iloc[:,-1]=encode_target(df,-1)\n",
    "\n",
    "# df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6, 11, 22, 33]\n",
      "[1, 2, 3, 11, 22, 33]\n",
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "for f in [[1,2,3],[4,5,6],[11,22,33]]:\n",
    "    h=list([[1,2,3],[4,5,6],[11,22,33]])\n",
    "    # print(h)\n",
    "    h.remove(f)\n",
    "    print(sum(h,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35022802, -1.70163072, -0.33832218],\n",
       "       [-0.10627487, -0.11439432, -0.36702633]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.random.randn(2, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31b4864f7a329bb7df33ee910d06966add06d4194ca7784060c0c775d42f1d3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
